{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain.vectorstores import FAISS\n",
    "import re\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/book_data.csv\").drop_duplicates(subset=[\"book_desc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_edition</th>\n",
       "      <th>book_format</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78044E+12</td>\n",
       "      <td>374 pages</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5519135</td>\n",
       "      <td>160706</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Young Adult|Fiction|Science Fiction|Dystopia|F...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling|Mary GrandPré</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>US Edition</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78044E+12</td>\n",
       "      <td>870 pages</td>\n",
       "      <td>4.48</td>\n",
       "      <td>2041594</td>\n",
       "      <td>33264</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Fantasy|Young Adult|Fiction</td>\n",
       "      <td>https://images.gr-assets.com/books/1255614970l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>50th Anniversary</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78006E+12</td>\n",
       "      <td>324 pages</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3745197</td>\n",
       "      <td>79450</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Classics|Fiction|Historical|Historical Fiction...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen|Anna Quindlen|Mrs. Oliphant|George...</td>\n",
       "      <td>«È cosa ormai risaputa che a uno scapolo in po...</td>\n",
       "      <td>Modern Library Classics, USA / CAN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78068E+12</td>\n",
       "      <td>279 pages</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2453620</td>\n",
       "      <td>54322</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Classics|Fiction|Romance</td>\n",
       "      <td>https://images.gr-assets.com/books/1320399351l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78032E+12</td>\n",
       "      <td>498 pages</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4281268</td>\n",
       "      <td>97991</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Young Adult|Fantasy|Romance|Paranormal|Vampire...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54295</th>\n",
       "      <td>Avi Steinberg</td>\n",
       "      <td>Avi Steinberg is stumped. After defecting from...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78039E+12</td>\n",
       "      <td>399 pages</td>\n",
       "      <td>3.51</td>\n",
       "      <td>3717</td>\n",
       "      <td>661</td>\n",
       "      <td>Running the Books: The Adventures of an Accide...</td>\n",
       "      <td>Nonfiction|Autobiography|Memoir|Biography|Writ...</td>\n",
       "      <td>https://images.gr-assets.com/books/1320533033l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54296</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>In this fearless and half-crazy story, Howard ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78161E+12</td>\n",
       "      <td>256 pages</td>\n",
       "      <td>3.37</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>Taking the Field: A Fan's Quest to Run the Tea...</td>\n",
       "      <td>Sports|Baseball|Sports and Games|Sports|Nonfic...</td>\n",
       "      <td>https://images.gr-assets.com/books/1312074392l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54297</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>From the icons of the game to the players who ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78006E+12</td>\n",
       "      <td>256 pages</td>\n",
       "      <td>3.97</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>The Baseball Talmud: Koufax, Greenberg, and th...</td>\n",
       "      <td>Nonfiction|Sports and Games|Sports</td>\n",
       "      <td>https://images.gr-assets.com/books/1348841629l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54299</th>\n",
       "      <td>Mimi Baird|Eve Claxton</td>\n",
       "      <td>Soon to be a major motion picture, from Brad P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.7808E+12</td>\n",
       "      <td>272 pages</td>\n",
       "      <td>3.82</td>\n",
       "      <td>867</td>\n",
       "      <td>187</td>\n",
       "      <td>He Wanted the Moon: The Madness and Medical Ge...</td>\n",
       "      <td>Nonfiction|Autobiography|Memoir|Biography|Psyc...</td>\n",
       "      <td>https://images.gr-assets.com/books/1403192135l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54300</th>\n",
       "      <td>Leah Price</td>\n",
       "      <td>The Anthology and the Rise of the Novel brings...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78052E+12</td>\n",
       "      <td>236 pages</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>The Anthology and the Rise of the Novel: From ...</td>\n",
       "      <td>Criticism|Literary Criticism|Philosophy|Theory...</td>\n",
       "      <td>https://images.gr-assets.com/books/1349014225l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51782 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            book_authors  \\\n",
       "0                                        Suzanne Collins   \n",
       "1                             J.K. Rowling|Mary GrandPré   \n",
       "2                                             Harper Lee   \n",
       "3      Jane Austen|Anna Quindlen|Mrs. Oliphant|George...   \n",
       "4                                        Stephenie Meyer   \n",
       "...                                                  ...   \n",
       "54295                                      Avi Steinberg   \n",
       "54296                                      Howard Megdal   \n",
       "54297                                      Howard Megdal   \n",
       "54299                             Mimi Baird|Eve Claxton   \n",
       "54300                                         Leah Price   \n",
       "\n",
       "                                               book_desc  \\\n",
       "0      Winning will make you famous. Losing means cer...   \n",
       "1      There is a door at the end of a silent corrido...   \n",
       "2      The unforgettable novel of a childhood in a sl...   \n",
       "3      «È cosa ormai risaputa che a uno scapolo in po...   \n",
       "4      About three things I was absolutely positive.F...   \n",
       "...                                                  ...   \n",
       "54295  Avi Steinberg is stumped. After defecting from...   \n",
       "54296  In this fearless and half-crazy story, Howard ...   \n",
       "54297  From the icons of the game to the players who ...   \n",
       "54299  Soon to be a major motion picture, from Brad P...   \n",
       "54300  The Anthology and the Rise of the Novel brings...   \n",
       "\n",
       "                             book_edition book_format    book_isbn book_pages  \\\n",
       "0                                     NaN   Hardcover  9.78044E+12  374 pages   \n",
       "1                              US Edition   Paperback  9.78044E+12  870 pages   \n",
       "2                        50th Anniversary   Paperback  9.78006E+12  324 pages   \n",
       "3      Modern Library Classics, USA / CAN   Paperback  9.78068E+12  279 pages   \n",
       "4                                     NaN   Paperback  9.78032E+12  498 pages   \n",
       "...                                   ...         ...          ...        ...   \n",
       "54295                                 NaN   Hardcover  9.78039E+12  399 pages   \n",
       "54296                                 NaN   Hardcover  9.78161E+12  256 pages   \n",
       "54297                                 NaN   Hardcover  9.78006E+12  256 pages   \n",
       "54299                                 NaN   Hardcover   9.7808E+12  272 pages   \n",
       "54300                                 NaN   Paperback  9.78052E+12  236 pages   \n",
       "\n",
       "       book_rating  book_rating_count  book_review_count  \\\n",
       "0             4.33            5519135             160706   \n",
       "1             4.48            2041594              33264   \n",
       "2             4.27            3745197              79450   \n",
       "3             4.25            2453620              54322   \n",
       "4             3.58            4281268              97991   \n",
       "...            ...                ...                ...   \n",
       "54295         3.51               3717                661   \n",
       "54296         3.37                 27                  9   \n",
       "54297         3.97                 34                  5   \n",
       "54299         3.82                867                187   \n",
       "54300         3.58                 12                  3   \n",
       "\n",
       "                                              book_title  \\\n",
       "0                                       The Hunger Games   \n",
       "1              Harry Potter and the Order of the Phoenix   \n",
       "2                                  To Kill a Mockingbird   \n",
       "3                                    Pride and Prejudice   \n",
       "4                                               Twilight   \n",
       "...                                                  ...   \n",
       "54295  Running the Books: The Adventures of an Accide...   \n",
       "54296  Taking the Field: A Fan's Quest to Run the Tea...   \n",
       "54297  The Baseball Talmud: Koufax, Greenberg, and th...   \n",
       "54299  He Wanted the Moon: The Madness and Medical Ge...   \n",
       "54300  The Anthology and the Rise of the Novel: From ...   \n",
       "\n",
       "                                                  genres  \\\n",
       "0      Young Adult|Fiction|Science Fiction|Dystopia|F...   \n",
       "1                            Fantasy|Young Adult|Fiction   \n",
       "2      Classics|Fiction|Historical|Historical Fiction...   \n",
       "3                               Classics|Fiction|Romance   \n",
       "4      Young Adult|Fantasy|Romance|Paranormal|Vampire...   \n",
       "...                                                  ...   \n",
       "54295  Nonfiction|Autobiography|Memoir|Biography|Writ...   \n",
       "54296  Sports|Baseball|Sports and Games|Sports|Nonfic...   \n",
       "54297                 Nonfiction|Sports and Games|Sports   \n",
       "54299  Nonfiction|Autobiography|Memoir|Biography|Psyc...   \n",
       "54300  Criticism|Literary Criticism|Philosophy|Theory...   \n",
       "\n",
       "                                               image_url  \n",
       "0      https://images.gr-assets.com/books/1447303603l...  \n",
       "1      https://images.gr-assets.com/books/1255614970l...  \n",
       "2      https://images.gr-assets.com/books/1361975680l...  \n",
       "3      https://images.gr-assets.com/books/1320399351l...  \n",
       "4      https://images.gr-assets.com/books/1361039443l...  \n",
       "...                                                  ...  \n",
       "54295  https://images.gr-assets.com/books/1320533033l...  \n",
       "54296  https://images.gr-assets.com/books/1312074392l...  \n",
       "54297  https://images.gr-assets.com/books/1348841629l...  \n",
       "54299  https://images.gr-assets.com/books/1403192135l...  \n",
       "54300  https://images.gr-assets.com/books/1349014225l...  \n",
       "\n",
       "[51782 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"book_desc\"].astype(str).apply(len) < 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp\\ipykernel_1508\\3486664887.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"book_desc\"] = df[\"book_desc\"].fillna('')\n"
     ]
    }
   ],
   "source": [
    "df[\"book_desc\"] = df[\"book_desc\"].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разобьем документ на чанки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstring = ' <s><s> '.join(df[\"book_desc\"].values[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_processing(data: str) -> str:\n",
    "    return re.sub(r'[\\r\\n\\t\\f\\v]+', '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = document_processing(docstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1121, which is longer than the specified 800\n",
      "Created a chunk of size 818, which is longer than the specified 800\n",
      "Created a chunk of size 814, which is longer than the specified 800\n",
      "Created a chunk of size 1141, which is longer than the specified 800\n",
      "Created a chunk of size 1089, which is longer than the specified 800\n",
      "Created a chunk of size 1116, which is longer than the specified 800\n",
      "Created a chunk of size 951, which is longer than the specified 800\n",
      "Created a chunk of size 1368, which is longer than the specified 800\n",
      "Created a chunk of size 1038, which is longer than the specified 800\n",
      "Created a chunk of size 1016, which is longer than the specified 800\n",
      "Created a chunk of size 1394, which is longer than the specified 800\n",
      "Created a chunk of size 948, which is longer than the specified 800\n",
      "Created a chunk of size 1479, which is longer than the specified 800\n",
      "Created a chunk of size 982, which is longer than the specified 800\n",
      "Created a chunk of size 916, which is longer than the specified 800\n",
      "Created a chunk of size 1335, which is longer than the specified 800\n",
      "Created a chunk of size 912, which is longer than the specified 800\n",
      "Created a chunk of size 983, which is longer than the specified 800\n",
      "Created a chunk of size 851, which is longer than the specified 800\n",
      "Created a chunk of size 898, which is longer than the specified 800\n",
      "Created a chunk of size 895, which is longer than the specified 800\n",
      "Created a chunk of size 1205, which is longer than the specified 800\n",
      "Created a chunk of size 1327, which is longer than the specified 800\n",
      "Created a chunk of size 972, which is longer than the specified 800\n",
      "Created a chunk of size 1117, which is longer than the specified 800\n",
      "Created a chunk of size 1065, which is longer than the specified 800\n",
      "Created a chunk of size 1177, which is longer than the specified 800\n",
      "Created a chunk of size 1325, which is longer than the specified 800\n",
      "Created a chunk of size 895, which is longer than the specified 800\n",
      "Created a chunk of size 1278, which is longer than the specified 800\n",
      "Created a chunk of size 1272, which is longer than the specified 800\n",
      "Created a chunk of size 915, which is longer than the specified 800\n",
      "Created a chunk of size 1098, which is longer than the specified 800\n",
      "Created a chunk of size 805, which is longer than the specified 800\n",
      "Created a chunk of size 1008, which is longer than the specified 800\n",
      "Created a chunk of size 1395, which is longer than the specified 800\n",
      "Created a chunk of size 830, which is longer than the specified 800\n",
      "Created a chunk of size 897, which is longer than the specified 800\n",
      "Created a chunk of size 804, which is longer than the specified 800\n",
      "Created a chunk of size 1478, which is longer than the specified 800\n",
      "Created a chunk of size 822, which is longer than the specified 800\n",
      "Created a chunk of size 1236, which is longer than the specified 800\n",
      "Created a chunk of size 813, which is longer than the specified 800\n",
      "Created a chunk of size 1279, which is longer than the specified 800\n",
      "Created a chunk of size 940, which is longer than the specified 800\n",
      "Created a chunk of size 825, which is longer than the specified 800\n",
      "Created a chunk of size 859, which is longer than the specified 800\n",
      "Created a chunk of size 1146, which is longer than the specified 800\n",
      "Created a chunk of size 1416, which is longer than the specified 800\n",
      "Created a chunk of size 911, which is longer than the specified 800\n",
      "Created a chunk of size 909, which is longer than the specified 800\n",
      "Created a chunk of size 843, which is longer than the specified 800\n",
      "Created a chunk of size 807, which is longer than the specified 800\n",
      "Created a chunk of size 985, which is longer than the specified 800\n",
      "Created a chunk of size 1170, which is longer than the specified 800\n",
      "Created a chunk of size 1132, which is longer than the specified 800\n",
      "Created a chunk of size 1141, which is longer than the specified 800\n",
      "Created a chunk of size 991, which is longer than the specified 800\n",
      "Created a chunk of size 821, which is longer than the specified 800\n",
      "Created a chunk of size 975, which is longer than the specified 800\n",
      "Created a chunk of size 975, which is longer than the specified 800\n",
      "Created a chunk of size 1019, which is longer than the specified 800\n",
      "Created a chunk of size 1014, which is longer than the specified 800\n",
      "Created a chunk of size 940, which is longer than the specified 800\n",
      "Created a chunk of size 856, which is longer than the specified 800\n",
      "Created a chunk of size 805, which is longer than the specified 800\n",
      "Created a chunk of size 1299, which is longer than the specified 800\n",
      "Created a chunk of size 850, which is longer than the specified 800\n",
      "Created a chunk of size 984, which is longer than the specified 800\n",
      "Created a chunk of size 1140, which is longer than the specified 800\n",
      "Created a chunk of size 1066, which is longer than the specified 800\n",
      "Created a chunk of size 1147, which is longer than the specified 800\n",
      "Created a chunk of size 1153, which is longer than the specified 800\n",
      "Created a chunk of size 1208, which is longer than the specified 800\n",
      "Created a chunk of size 1260, which is longer than the specified 800\n",
      "Created a chunk of size 820, which is longer than the specified 800\n",
      "Created a chunk of size 945, which is longer than the specified 800\n",
      "Created a chunk of size 1108, which is longer than the specified 800\n",
      "Created a chunk of size 877, which is longer than the specified 800\n",
      "Created a chunk of size 1349, which is longer than the specified 800\n",
      "Created a chunk of size 935, which is longer than the specified 800\n",
      "Created a chunk of size 890, which is longer than the specified 800\n",
      "Created a chunk of size 802, which is longer than the specified 800\n",
      "Created a chunk of size 1145, which is longer than the specified 800\n",
      "Created a chunk of size 1158, which is longer than the specified 800\n",
      "Created a chunk of size 890, which is longer than the specified 800\n",
      "Created a chunk of size 1143, which is longer than the specified 800\n",
      "Created a chunk of size 1375, which is longer than the specified 800\n",
      "Created a chunk of size 936, which is longer than the specified 800\n",
      "Created a chunk of size 1124, which is longer than the specified 800\n",
      "Created a chunk of size 1115, which is longer than the specified 800\n",
      "Created a chunk of size 1448, which is longer than the specified 800\n",
      "Created a chunk of size 879, which is longer than the specified 800\n",
      "Created a chunk of size 1476, which is longer than the specified 800\n",
      "Created a chunk of size 1193, which is longer than the specified 800\n",
      "Created a chunk of size 1205, which is longer than the specified 800\n",
      "Created a chunk of size 1185, which is longer than the specified 800\n",
      "Created a chunk of size 912, which is longer than the specified 800\n",
      "Created a chunk of size 811, which is longer than the specified 800\n",
      "Created a chunk of size 881, which is longer than the specified 800\n",
      "Created a chunk of size 856, which is longer than the specified 800\n",
      "Created a chunk of size 844, which is longer than the specified 800\n",
      "Created a chunk of size 826, which is longer than the specified 800\n",
      "Created a chunk of size 985, which is longer than the specified 800\n",
      "Created a chunk of size 1160, which is longer than the specified 800\n",
      "Created a chunk of size 1162, which is longer than the specified 800\n",
      "Created a chunk of size 1047, which is longer than the specified 800\n",
      "Created a chunk of size 974, which is longer than the specified 800\n",
      "Created a chunk of size 859, which is longer than the specified 800\n",
      "Created a chunk of size 1039, which is longer than the specified 800\n",
      "Created a chunk of size 885, which is longer than the specified 800\n",
      "Created a chunk of size 1166, which is longer than the specified 800\n",
      "Created a chunk of size 804, which is longer than the specified 800\n",
      "Created a chunk of size 830, which is longer than the specified 800\n",
      "Created a chunk of size 928, which is longer than the specified 800\n",
      "Created a chunk of size 885, which is longer than the specified 800\n",
      "Created a chunk of size 958, which is longer than the specified 800\n",
      "Created a chunk of size 939, which is longer than the specified 800\n",
      "Created a chunk of size 802, which is longer than the specified 800\n",
      "Created a chunk of size 1154, which is longer than the specified 800\n",
      "Created a chunk of size 1271, which is longer than the specified 800\n",
      "Created a chunk of size 1339, which is longer than the specified 800\n",
      "Created a chunk of size 979, which is longer than the specified 800\n",
      "Created a chunk of size 906, which is longer than the specified 800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "source_chunks = []\n",
    "splitter = CharacterTextSplitter(        \n",
    "    separator = \" <s><s> \",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "for chunk in splitter.split_text(document):\n",
    "    source_chunks.append(Document(page_content=chunk, metadata={}))\n",
    "\n",
    "# всего получилось чанков:\n",
    "len(source_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_chunks = []\n",
    "# # splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "\n",
    "# for chunk in document.split(\" <s><s> \"):\n",
    "#     source_chunks.append(Document(page_content=chunk, metadata={}))\n",
    "\n",
    "# # всего получилось чанков:\n",
    "# len(source_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализируем модель для эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S\\PycharmProjects\\SimilarBooksRecommendation\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('sergeyzh/rubert-tiny-turbo')\n",
    "\n",
    "# sentences = [\"привет мир\", \"hello world\", \"здравствуй вселенная\"]\n",
    "# embeddings = model.encode(sentences)\n",
    "# print(util.dot_score(embeddings, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='sergeyzh/rubert-tiny-turbo',  # distilbert-base-uncased  sergeyzh/rubert-tiny-turbo\n",
    "    # multi_process=True,\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализируем векторную базу Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(source_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/vector_db.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(db, 'models/vector_db.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simillar_book(book_desc: str, index_db: FAISS, n_chunks: int = 5) -> str:\n",
    "    # Поиск релевантных отрезков из базы знаний\n",
    "    docs = index_db.similarity_search(book_desc, k=n_chunks)\n",
    "\n",
    "    # message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\nОтрывок документа №{i+1}\\n=====================' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Получим похожие книги на 1ю в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_desc = df[\"book_desc\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_content = get_simillar_book(book_desc=book_desc, index_db=db, n_chunks=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = [desc.page_content for desc in message_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>The Hunger Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Veronica Roth</td>\n",
       "      <td>Divergent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Louisa May Alcott</td>\n",
       "      <td>Little Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Veronica Roth</td>\n",
       "      <td>Insurgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Catching Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Kristin Cashore</td>\n",
       "      <td>Graceling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          book_authors        book_title\n",
       "0      Suzanne Collins  The Hunger Games\n",
       "19       Veronica Roth         Divergent\n",
       "77   Louisa May Alcott      Little Women\n",
       "153      Veronica Roth         Insurgent\n",
       "262    Suzanne Collins     Catching Fire\n",
       "292    Kristin Cashore         Graceling"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"book_desc\"].isin(descs)][[\"book_authors\", \"book_title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qdrant исследование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
